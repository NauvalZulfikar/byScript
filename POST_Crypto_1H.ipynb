{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "6lz13K5ib3Ic",
        "ti7CR7tUT414",
        "29YqTdLzNlRH"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NauvalZulfikar/byScript/blob/main/POST_Crypto_1H.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIBRARY"
      ],
      "metadata": {
        "id": "5CwzUC3k1Pck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "def post_data_in_chunks(df, coin, post_url, headers, chunk_size=5000):\n",
        "    \"\"\"Splits large dataframes into smaller chunks and posts them to the API.\"\"\"\n",
        "\n",
        "    num_chunks = math.ceil(len(df) / chunk_size)\n",
        "\n",
        "    for i in range(num_chunks):\n",
        "        chunk = df.iloc[i * chunk_size: (i + 1) * chunk_size].copy()\n",
        "        chunk[\"Datetime\"] = chunk[\"Datetime\"].astype(str)  # Convert Timestamp to string\n",
        "\n",
        "        json_data = {f\"{coin}USDT\": chunk.to_dict(orient=\"records\")}\n",
        "\n",
        "        try:\n",
        "            post_response = requests.post(post_url, json=json_data, headers=headers)\n",
        "\n",
        "            if post_response.status_code in [200, 201]:\n",
        "                print(f\"‚úÖ Successfully posted chunk {i+1}/{num_chunks} for {coin}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Error posting chunk {i+1}/{num_chunks} for {coin}: {post_response.status_code}, {post_response.text}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"üö® Exception posting chunk {i+1}/{num_chunks} for {coin}: {e}\")\n",
        "\n",
        "        time.sleep(1)  # Prevent excessive API requests\n",
        "\n",
        "def fetch_and_post_data(coin, API_KEY):\n",
        "    BASE_URL = \"https://min-api.cryptocompare.com/data/v2/histohour\"\n",
        "    start_date = \"2017-01-01 00:00:00\"\n",
        "    end_date = \"2025-12-31 23:59:59\"\n",
        "\n",
        "    adjusted_start_date = pd.Timestamp(start_date) - pd.Timedelta(hours=2007)  # 2000 + 7 hours\n",
        "    start_timestamp = int(pd.Timestamp(adjusted_start_date).timestamp())\n",
        "    end_timestamp = int(pd.Timestamp(end_date).timestamp())\n",
        "\n",
        "    all_data = []\n",
        "    current_timestamp = end_timestamp\n",
        "\n",
        "    try:\n",
        "        while current_timestamp > start_timestamp:\n",
        "            params = {\n",
        "                \"fsym\": coin,\n",
        "                \"tsym\": \"USDT\",\n",
        "                \"limit\": 2000,\n",
        "                \"aggregate\": 1,\n",
        "                \"toTs\": current_timestamp,\n",
        "                \"e\": \"Binance\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(BASE_URL, headers={\"authorization\": f\"Apikey {API_KEY}\"}, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json().get(\"Data\", {}).get(\"Data\", [])\n",
        "                if not data:\n",
        "                    break\n",
        "\n",
        "                all_data.extend(data)\n",
        "                current_timestamp = data[0][\"time\"]\n",
        "                time.sleep(1)  # Prevent hitting API rate limits\n",
        "\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Error fetching data for {coin}: {response.status_code}, {response.text}\")\n",
        "                return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"üö® Exception fetching data for {coin}: {e}\")\n",
        "        return None\n",
        "\n",
        "    if not all_data:\n",
        "        print(f\"‚ö†Ô∏è No data retrieved for {coin}. Exiting.\")\n",
        "        return None\n",
        "\n",
        "    # Convert collected data into a DataFrame\n",
        "    df = pd.DataFrame(all_data)\n",
        "\n",
        "    # Convert UNIX timestamp to datetime (UTC first, then UTC+7)\n",
        "    df[\"Datetime\"] = pd.to_datetime(df[\"time\"], unit=\"s\", utc=True).dt.tz_convert(\"Asia/Bangkok\")\n",
        "    df.drop(columns=[\"time\"], inplace=True)\n",
        "\n",
        "    # Rename columns for clarity\n",
        "    df.rename(columns={\"volumefrom\": f\"volume_{coin}\", \"volumeto\": \"volume_USDT\"}, inplace=True)\n",
        "\n",
        "    # Sort by Datetime\n",
        "    df = df.sort_values(\"Datetime\").reset_index(drop=True)\n",
        "\n",
        "    # Remove consecutive duplicate rows (excluding \"Datetime\")\n",
        "    df_cleaned = df.loc[df.drop(columns=[\"Datetime\"]).apply(tuple, axis=1).shift() != df.drop(columns=[\"Datetime\"]).apply(tuple, axis=1)]\n",
        "    df_cleaned = df_cleaned.reset_index(drop=True).iloc[1:].reset_index(drop=True)\n",
        "\n",
        "    if df_cleaned.empty:\n",
        "        print(f\"‚ö†Ô∏è No valid data to send for {coin}. Skipping API request.\")\n",
        "        return None\n",
        "\n",
        "    # API POST request to byscript.io\n",
        "    post_url = \"https://byscript.io/api/feed-data/\"\n",
        "    headers = {\"accept\": \"application/json\", \"Content-type\": \"application/json\"}\n",
        "\n",
        "    post_data_in_chunks(df_cleaned, coin, post_url, headers, chunk_size=5000)\n",
        "\n",
        "    print(f\"‚úÖ Finished processing {coin}\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "top_100_crypto_symbols = [\n",
        "    'BTC', 'ETH', 'XRP', 'USDT', 'BNB', 'SOL', 'USDC', 'DOGE', 'ADA', 'TRX',\n",
        "    'LINK', 'SUI', 'AVAX', 'XLM', 'LTC', 'HBAR', 'SHIB', 'LEO', 'TON', 'HYPE',\n",
        "    'DOT', 'OM', 'BCH', 'USDe', 'UNI', 'BGB', 'DAI', 'XMR', 'NEAR', 'PEPE',\n",
        "    'AAVE', 'TAO', 'ONDO', 'APT', 'MNT', 'ICP', 'TRUMP', 'ETC', 'OKB', 'KAS',\n",
        "    'S', 'VET', 'POL', 'RNDR', 'ALGO', 'CRO', 'FIL', 'ARB', 'JUP', 'GT',\n",
        "    'FDUSD', 'TIA', 'ATOM', 'OP', 'FET', 'LDO', 'DEXE', 'INJ', 'KCS', 'STX',\n",
        "    'XDC', 'RAY', 'THETA', 'GRT', 'SEI', 'IMX', 'ENA', 'WLD', 'BONK', 'IP',\n",
        "    'MOVE', 'MKR', 'QNT', 'FLR', 'JASMY', 'EOS', 'ENS', 'JTO', 'FLOKI', 'XTZ',\n",
        "    'SAND', 'PYTH', 'BERA', 'NEXO', 'GALA', 'BTT', 'IOTA', 'FLOW', 'KAIA',\n",
        "    'RON', 'NEO', 'BSV', 'CAKE', 'VIRTUAL', 'XAUt', 'AXS', 'PYUSD', 'CRV',\n",
        "    'MELANIA', 'SPX'\n",
        "]\n",
        "\n",
        "API_KEY = \"05928b70dcbeba8844727ad0142f8b86e92fd5d6a3a29881d1cd3300d2c27ecf\"\n",
        "for i in top_100_crypto_symbols:\n",
        "  coin = i\n",
        "  fetch_and_post_data(coin, API_KEY)"
      ],
      "metadata": {
        "id": "020bB2_ng3wA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}